{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from typing import Tuple, List, Dict\n",
    "import os\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_train = (0, 400)\n",
    "dates_test = (401, 480)\n",
    "num_models = {\"cat\": 1}\n",
    "models_path = \"./models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title params dashboard\n",
    "params = {\n",
    "    \"learning_rate\": 0.005,  # 0.005,0.05\n",
    "    \"depth\": 14,  # 14\n",
    "    \"iterations\": 10000,\n",
    "    \"l2_leaf_reg\": 0.1,  # 511,31,1023\n",
    "    \"loss_function\": \"MAE\",\n",
    "    \"subsample\": 0.2,\n",
    "    \"rsm\": 0.3,\n",
    "    \"thread_count\": 7,\n",
    "    \"cat_features\": [\"seconds_in_bucket\"],\n",
    "    # \"device\": \"gpu\",\n",
    "    # 'reg_alpha'         : 0.1,\n",
    "    # 'reg_lambda'        : 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_date(df: pl.DataFrame, dates: Tuple[int, int]) -> pl.DataFrame:\n",
    "    return df.filter(\n",
    "        pl.col(\"date_id\").ge(dates[0]).and_(pl.col(\"date_id\").le(dates[1]))\n",
    "    )\n",
    "\n",
    "\n",
    "def make_predictions(models, X_test, model=\"nn\"):\n",
    "    if model == \"nn\":\n",
    "        all_predictions = [model.predict(X_test, batch_size=16384) for model in models]\n",
    "    if model == \"lgb\":\n",
    "        all_predictions = [\n",
    "            model.predict(X_test, num_iteration=model.best_iteration)\n",
    "            for model in models\n",
    "        ]\n",
    "    if model == \"xgb\":\n",
    "        all_predictions = [\n",
    "            model.predict(\n",
    "                X_test, iteration_range=(0, model.get_booster().best_iteration + 1)\n",
    "            )\n",
    "            for model in models\n",
    "        ]\n",
    "    if model == \"cat\":\n",
    "        all_predictions = [model.predict(X_test) for model in models]\n",
    "    prediction = np.mean(all_predictions, axis=0)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have 272 catboost features\n"
     ]
    }
   ],
   "source": [
    "excluded_columns = [\"row_id\", \"date_id\", \"time_id\", \"target\", \"stock_return\"]\n",
    "\n",
    "train_eng = pl.read_parquet(\"data/train_eng.parquet\")\n",
    "lgb_features = [\n",
    "    col for col in train_eng.schema.keys() if col not in excluded_columns\n",
    "]\n",
    "categorical_features = [\"seconds_in_bucket\"]\n",
    "\n",
    "print(\"we have {} catboost features\".format(len(lgb_features)))\n",
    "\n",
    "train_data = split_by_date(train_eng, dates_train)\n",
    "test_data = split_by_date(train_eng, dates_test)\n",
    "\n",
    "\n",
    "X_train, y_train = (\n",
    "    train_data.select(pl.col(lgb_features)).to_pandas(),\n",
    "    train_data.select(pl.col(\"target\")).to_pandas(),\n",
    ")\n",
    "X_test, y_test = (\n",
    "    test_data.select(pl.col(lgb_features)).to_pandas(),\n",
    "    test_data.select(pl.col(\"target\")).to_pandas(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[categorical_features] = X_train[categorical_features].astype(\"category\")\n",
    "X_test[categorical_features] = X_test[categorical_features].astype(\"category\")\n",
    "\n",
    "del train_data, test_data, train_eng\n",
    "import gc\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 1 out of 1 with seed 42\n",
      "---------------------------------------\n",
      "0:\tlearn: 6.4891808\ttest: 5.9965605\tbest: 5.9965605 (0)\ttotal: 1.34s\tremaining: 3h 43m 31s\n",
      "50:\tlearn: 6.4427142\ttest: 5.9628494\tbest: 5.9628494 (50)\ttotal: 1m 23s\tremaining: 4h 32m 11s\n",
      "100:\tlearn: 6.4086925\ttest: 5.9399041\tbest: 5.9399041 (100)\ttotal: 2m 42s\tremaining: 4h 24m 48s\n",
      "150:\tlearn: 6.3827563\ttest: 5.9240821\tbest: 5.9240821 (150)\ttotal: 4m 2s\tremaining: 4h 23m 35s\n",
      "200:\tlearn: 6.3626064\ttest: 5.9131365\tbest: 5.9131365 (200)\ttotal: 5m 20s\tremaining: 4h 20m 39s\n",
      "250:\tlearn: 6.3461164\ttest: 5.9054165\tbest: 5.9054165 (250)\ttotal: 6m 40s\tremaining: 4h 19m 14s\n",
      "300:\tlearn: 6.3318799\ttest: 5.8993696\tbest: 5.8993696 (300)\ttotal: 8m 1s\tremaining: 4h 18m 41s\n",
      "350:\tlearn: 6.3195062\ttest: 5.8948430\tbest: 5.8948430 (350)\ttotal: 9m 20s\tremaining: 4h 16m 34s\n",
      "400:\tlearn: 6.3085778\ttest: 5.8914760\tbest: 5.8914760 (400)\ttotal: 10m 37s\tremaining: 4h 14m 17s\n",
      "450:\tlearn: 6.2983699\ttest: 5.8885774\tbest: 5.8885774 (450)\ttotal: 11m 53s\tremaining: 4h 11m 54s\n",
      "500:\tlearn: 6.2888755\ttest: 5.8859873\tbest: 5.8859873 (500)\ttotal: 13m 15s\tremaining: 4h 11m 19s\n",
      "550:\tlearn: 6.2798884\ttest: 5.8839269\tbest: 5.8839269 (550)\ttotal: 14m 39s\tremaining: 4h 11m 23s\n",
      "600:\tlearn: 6.2710683\ttest: 5.8819444\tbest: 5.8819444 (600)\ttotal: 16m 1s\tremaining: 4h 10m 37s\n",
      "650:\tlearn: 6.2626850\ttest: 5.8803014\tbest: 5.8803014 (650)\ttotal: 17m 25s\tremaining: 4h 10m 21s\n",
      "700:\tlearn: 6.2544296\ttest: 5.8788484\tbest: 5.8788484 (700)\ttotal: 18m 43s\tremaining: 4h 8m 24s\n",
      "750:\tlearn: 6.2463451\ttest: 5.8776130\tbest: 5.8776130 (750)\ttotal: 19m 58s\tremaining: 4h 6m 4s\n",
      "800:\tlearn: 6.2387036\ttest: 5.8762911\tbest: 5.8762911 (800)\ttotal: 21m 18s\tremaining: 4h 4m 45s\n",
      "850:\tlearn: 6.2312160\ttest: 5.8751565\tbest: 5.8751565 (850)\ttotal: 22m 36s\tremaining: 4h 3m\n",
      "900:\tlearn: 6.2241315\ttest: 5.8739897\tbest: 5.8739897 (900)\ttotal: 23m 54s\tremaining: 4h 1m 28s\n",
      "950:\tlearn: 6.2173324\ttest: 5.8730735\tbest: 5.8730735 (950)\ttotal: 25m 10s\tremaining: 3h 59m 28s\n",
      "1000:\tlearn: 6.2104368\ttest: 5.8721609\tbest: 5.8721609 (1000)\ttotal: 26m 27s\tremaining: 3h 57m 50s\n",
      "1050:\tlearn: 6.2035055\ttest: 5.8712520\tbest: 5.8712520 (1050)\ttotal: 27m 44s\tremaining: 3h 56m 12s\n",
      "1100:\tlearn: 6.1967953\ttest: 5.8705255\tbest: 5.8705255 (1100)\ttotal: 28m 59s\tremaining: 3h 54m 19s\n",
      "1150:\tlearn: 6.1903939\ttest: 5.8699180\tbest: 5.8699180 (1150)\ttotal: 30m 11s\tremaining: 3h 52m 8s\n",
      "1200:\tlearn: 6.1840005\ttest: 5.8691988\tbest: 5.8691988 (1200)\ttotal: 31m 26s\tremaining: 3h 50m 20s\n",
      "1250:\tlearn: 6.1777540\ttest: 5.8685710\tbest: 5.8685710 (1250)\ttotal: 32m 40s\tremaining: 3h 48m 31s\n",
      "1300:\tlearn: 6.1717678\ttest: 5.8680256\tbest: 5.8680256 (1300)\ttotal: 33m 54s\tremaining: 3h 46m 43s\n",
      "1350:\tlearn: 6.1659974\ttest: 5.8673988\tbest: 5.8673988 (1350)\ttotal: 35m 7s\tremaining: 3h 44m 53s\n",
      "1400:\tlearn: 6.1598562\ttest: 5.8667881\tbest: 5.8667881 (1400)\ttotal: 36m 21s\tremaining: 3h 43m 12s\n",
      "1450:\tlearn: 6.1541886\ttest: 5.8663806\tbest: 5.8663806 (1450)\ttotal: 37m 35s\tremaining: 3h 41m 29s\n",
      "1500:\tlearn: 6.1485025\ttest: 5.8658911\tbest: 5.8658911 (1500)\ttotal: 38m 48s\tremaining: 3h 39m 45s\n",
      "1550:\tlearn: 6.1426108\ttest: 5.8654632\tbest: 5.8654632 (1550)\ttotal: 40m 3s\tremaining: 3h 38m 13s\n",
      "1600:\tlearn: 6.1372454\ttest: 5.8650631\tbest: 5.8650631 (1600)\ttotal: 41m 17s\tremaining: 3h 36m 37s\n",
      "1650:\tlearn: 6.1316918\ttest: 5.8646344\tbest: 5.8646340 (1649)\ttotal: 42m 32s\tremaining: 3h 35m 7s\n",
      "1700:\tlearn: 6.1261466\ttest: 5.8642193\tbest: 5.8642193 (1700)\ttotal: 43m 46s\tremaining: 3h 33m 36s\n",
      "1750:\tlearn: 6.1208157\ttest: 5.8638638\tbest: 5.8638638 (1750)\ttotal: 45m 2s\tremaining: 3h 32m 9s\n",
      "1800:\tlearn: 6.1155495\ttest: 5.8636012\tbest: 5.8636012 (1800)\ttotal: 46m 15s\tremaining: 3h 30m 33s\n",
      "1850:\tlearn: 6.1101635\ttest: 5.8633399\tbest: 5.8633399 (1850)\ttotal: 47m 30s\tremaining: 3h 29m 7s\n",
      "1900:\tlearn: 6.1047092\ttest: 5.8630409\tbest: 5.8630409 (1900)\ttotal: 48m 47s\tremaining: 3h 27m 50s\n",
      "1950:\tlearn: 6.0996392\ttest: 5.8627347\tbest: 5.8627347 (1950)\ttotal: 50m 2s\tremaining: 3h 26m 27s\n",
      "2000:\tlearn: 6.0949935\ttest: 5.8625174\tbest: 5.8625174 (2000)\ttotal: 51m 18s\tremaining: 3h 25m 6s\n",
      "2050:\tlearn: 6.0898170\ttest: 5.8623117\tbest: 5.8623117 (2050)\ttotal: 52m 32s\tremaining: 3h 23m 38s\n",
      "2100:\tlearn: 6.0849819\ttest: 5.8620134\tbest: 5.8620134 (2100)\ttotal: 53m 47s\tremaining: 3h 22m 15s\n",
      "2150:\tlearn: 6.0801188\ttest: 5.8618275\tbest: 5.8618239 (2148)\ttotal: 55m 3s\tremaining: 3h 20m 54s\n",
      "2200:\tlearn: 6.0754756\ttest: 5.8616298\tbest: 5.8616298 (2200)\ttotal: 56m 20s\tremaining: 3h 19m 36s\n",
      "2250:\tlearn: 6.0706240\ttest: 5.8614464\tbest: 5.8614448 (2249)\ttotal: 57m 34s\tremaining: 3h 18m 12s\n",
      "2300:\tlearn: 6.0661994\ttest: 5.8612242\tbest: 5.8612242 (2300)\ttotal: 58m 51s\tremaining: 3h 16m 54s\n",
      "2350:\tlearn: 6.0615906\ttest: 5.8610869\tbest: 5.8610829 (2349)\ttotal: 1h 9s\tremaining: 3h 15m 43s\n",
      "2400:\tlearn: 6.0572604\ttest: 5.8609408\tbest: 5.8609364 (2399)\ttotal: 1h 1m 23s\tremaining: 3h 14m 18s\n",
      "2450:\tlearn: 6.0529986\ttest: 5.8607299\tbest: 5.8607299 (2450)\ttotal: 1h 2m 34s\tremaining: 3h 12m 44s\n",
      "2500:\tlearn: 6.0485889\ttest: 5.8605670\tbest: 5.8605670 (2500)\ttotal: 1h 3m 44s\tremaining: 3h 11m 8s\n",
      "2550:\tlearn: 6.0443427\ttest: 5.8603962\tbest: 5.8603962 (2550)\ttotal: 1h 4m 55s\tremaining: 3h 9m 34s\n",
      "2600:\tlearn: 6.0402251\ttest: 5.8602971\tbest: 5.8602932 (2598)\ttotal: 1h 6m 5s\tremaining: 3h 7m 59s\n",
      "2650:\tlearn: 6.0360995\ttest: 5.8601420\tbest: 5.8601399 (2649)\ttotal: 1h 7m 18s\tremaining: 3h 6m 34s\n",
      "2700:\tlearn: 6.0320982\ttest: 5.8600162\tbest: 5.8600145 (2698)\ttotal: 1h 8m 29s\tremaining: 3h 5m 5s\n",
      "2750:\tlearn: 6.0281706\ttest: 5.8599440\tbest: 5.8599440 (2750)\ttotal: 1h 9m 41s\tremaining: 3h 3m 37s\n",
      "2800:\tlearn: 6.0243970\ttest: 5.8598429\tbest: 5.8598386 (2797)\ttotal: 1h 10m 57s\tremaining: 3h 2m 23s\n",
      "2850:\tlearn: 6.0205781\ttest: 5.8597535\tbest: 5.8597535 (2850)\ttotal: 1h 12m 9s\tremaining: 3h 57s\n",
      "2900:\tlearn: 6.0167134\ttest: 5.8596090\tbest: 5.8596090 (2900)\ttotal: 1h 13m 25s\tremaining: 2h 59m 41s\n",
      "2950:\tlearn: 6.0131679\ttest: 5.8594981\tbest: 5.8594964 (2949)\ttotal: 1h 14m 44s\tremaining: 2h 58m 31s\n",
      "3000:\tlearn: 6.0096126\ttest: 5.8594048\tbest: 5.8594048 (3000)\ttotal: 1h 15m 59s\tremaining: 2h 57m 13s\n",
      "3050:\tlearn: 6.0062361\ttest: 5.8593313\tbest: 5.8593307 (3048)\ttotal: 1h 17m 15s\tremaining: 2h 55m 57s\n",
      "3100:\tlearn: 6.0026292\ttest: 5.8592418\tbest: 5.8592417 (3099)\ttotal: 1h 18m 30s\tremaining: 2h 54m 39s\n",
      "3150:\tlearn: 5.9992164\ttest: 5.8591091\tbest: 5.8591091 (3150)\ttotal: 1h 19m 48s\tremaining: 2h 53m 27s\n",
      "3200:\tlearn: 5.9958685\ttest: 5.8590617\tbest: 5.8590584 (3198)\ttotal: 1h 21m 4s\tremaining: 2h 52m 12s\n",
      "3250:\tlearn: 5.9926259\ttest: 5.8590192\tbest: 5.8590181 (3249)\ttotal: 1h 22m 17s\tremaining: 2h 50m 49s\n",
      "3300:\tlearn: 5.9894275\ttest: 5.8589810\tbest: 5.8589785 (3299)\ttotal: 1h 23m 33s\tremaining: 2h 49m 33s\n",
      "3350:\tlearn: 5.9861153\ttest: 5.8589286\tbest: 5.8589286 (3350)\ttotal: 1h 24m 49s\tremaining: 2h 48m 17s\n",
      "3400:\tlearn: 5.9828842\ttest: 5.8588976\tbest: 5.8588952 (3398)\ttotal: 1h 26m 1s\tremaining: 2h 46m 54s\n",
      "3450:\tlearn: 5.9796972\ttest: 5.8588364\tbest: 5.8588319 (3446)\ttotal: 1h 27m 13s\tremaining: 2h 45m 30s\n",
      "3500:\tlearn: 5.9766896\ttest: 5.8587778\tbest: 5.8587778 (3500)\ttotal: 1h 28m 27s\tremaining: 2h 44m 13s\n",
      "3550:\tlearn: 5.9738716\ttest: 5.8587253\tbest: 5.8587253 (3550)\ttotal: 1h 29m 43s\tremaining: 2h 42m 56s\n",
      "3600:\tlearn: 5.9709159\ttest: 5.8586663\tbest: 5.8586663 (3600)\ttotal: 1h 30m 57s\tremaining: 2h 41m 38s\n",
      "3650:\tlearn: 5.9679959\ttest: 5.8586173\tbest: 5.8586173 (3650)\ttotal: 1h 32m 12s\tremaining: 2h 40m 20s\n",
      "3700:\tlearn: 5.9650828\ttest: 5.8585547\tbest: 5.8585547 (3700)\ttotal: 1h 33m 27s\tremaining: 2h 39m 3s\n",
      "3750:\tlearn: 5.9623365\ttest: 5.8585364\tbest: 5.8585364 (3750)\ttotal: 1h 34m 43s\tremaining: 2h 37m 48s\n",
      "3800:\tlearn: 5.9595893\ttest: 5.8584592\tbest: 5.8584536 (3795)\ttotal: 1h 35m 59s\tremaining: 2h 36m 33s\n",
      "3850:\tlearn: 5.9569858\ttest: 5.8584245\tbest: 5.8584245 (3850)\ttotal: 1h 37m 12s\tremaining: 2h 35m 13s\n",
      "3900:\tlearn: 5.9540154\ttest: 5.8584257\tbest: 5.8584177 (3864)\ttotal: 1h 38m 26s\tremaining: 2h 33m 54s\n",
      "3950:\tlearn: 5.9511839\ttest: 5.8583988\tbest: 5.8583851 (3926)\ttotal: 1h 39m 41s\tremaining: 2h 32m 37s\n",
      "4000:\tlearn: 5.9485686\ttest: 5.8583364\tbest: 5.8583363 (3998)\ttotal: 1h 40m 56s\tremaining: 2h 31m 21s\n",
      "4050:\tlearn: 5.9459550\ttest: 5.8582989\tbest: 5.8582919 (4043)\ttotal: 1h 42m 11s\tremaining: 2h 30m 4s\n",
      "4100:\tlearn: 5.9434332\ttest: 5.8582777\tbest: 5.8582770 (4099)\ttotal: 1h 43m 26s\tremaining: 2h 28m 47s\n",
      "4150:\tlearn: 5.9409109\ttest: 5.8582644\tbest: 5.8582627 (4136)\ttotal: 1h 44m 39s\tremaining: 2h 27m 28s\n",
      "4200:\tlearn: 5.9384292\ttest: 5.8582365\tbest: 5.8582306 (4196)\ttotal: 1h 45m 55s\tremaining: 2h 26m 12s\n",
      "4250:\tlearn: 5.9358483\ttest: 5.8582115\tbest: 5.8582115 (4250)\ttotal: 1h 47m 7s\tremaining: 2h 24m 52s\n",
      "4300:\tlearn: 5.9332943\ttest: 5.8582143\tbest: 5.8582002 (4286)\ttotal: 1h 48m 21s\tremaining: 2h 23m 34s\n",
      "4350:\tlearn: 5.9308919\ttest: 5.8582176\tbest: 5.8582002 (4286)\ttotal: 1h 49m 36s\tremaining: 2h 22m 17s\n",
      "4400:\tlearn: 5.9284376\ttest: 5.8581828\tbest: 5.8581828 (4400)\ttotal: 1h 50m 52s\tremaining: 2h 21m 2s\n",
      "4450:\tlearn: 5.9259209\ttest: 5.8581409\tbest: 5.8581380 (4445)\ttotal: 1h 52m 5s\tremaining: 2h 19m 43s\n",
      "4500:\tlearn: 5.9235179\ttest: 5.8581515\tbest: 5.8581346 (4466)\ttotal: 1h 53m 19s\tremaining: 2h 18m 26s\n",
      "4550:\tlearn: 5.9212076\ttest: 5.8581234\tbest: 5.8581234 (4550)\ttotal: 1h 54m 33s\tremaining: 2h 17m 9s\n",
      "4600:\tlearn: 5.9189726\ttest: 5.8581183\tbest: 5.8581094 (4581)\ttotal: 1h 55m 46s\tremaining: 2h 15m 51s\n",
      "4650:\tlearn: 5.9168158\ttest: 5.8580887\tbest: 5.8580876 (4642)\ttotal: 1h 56m 59s\tremaining: 2h 14m 33s\n",
      "4700:\tlearn: 5.9147135\ttest: 5.8580975\tbest: 5.8580876 (4642)\ttotal: 1h 58m 11s\tremaining: 2h 13m 13s\n",
      "4750:\tlearn: 5.9125933\ttest: 5.8580809\tbest: 5.8580794 (4733)\ttotal: 1h 59m 24s\tremaining: 2h 11m 55s\n",
      "4800:\tlearn: 5.9104347\ttest: 5.8580676\tbest: 5.8580659 (4799)\ttotal: 2h 37s\tremaining: 2h 10m 37s\n",
      "4850:\tlearn: 5.9083184\ttest: 5.8580542\tbest: 5.8580509 (4847)\ttotal: 2h 1m 48s\tremaining: 2h 9m 17s\n",
      "4900:\tlearn: 5.9061831\ttest: 5.8580614\tbest: 5.8580477 (4873)\ttotal: 2h 3m 2s\tremaining: 2h 8m\n",
      "4950:\tlearn: 5.9041087\ttest: 5.8580495\tbest: 5.8580474 (4946)\ttotal: 2h 4m 14s\tremaining: 2h 6m 41s\n",
      "5000:\tlearn: 5.9019746\ttest: 5.8580433\tbest: 5.8580415 (4997)\ttotal: 2h 5m 30s\tremaining: 2h 5m 27s\n",
      "5050:\tlearn: 5.8999606\ttest: 5.8580318\tbest: 5.8580304 (5042)\ttotal: 2h 6m 44s\tremaining: 2h 4m 11s\n",
      "5100:\tlearn: 5.8979507\ttest: 5.8580349\tbest: 5.8580290 (5052)\ttotal: 2h 7m 57s\tremaining: 2h 2m 53s\n",
      "5150:\tlearn: 5.8960404\ttest: 5.8580415\tbest: 5.8580290 (5052)\ttotal: 2h 9m 13s\tremaining: 2h 1m 38s\n",
      "5200:\tlearn: 5.8939980\ttest: 5.8580377\tbest: 5.8580290 (5052)\ttotal: 2h 10m 26s\tremaining: 2h 21s\n",
      "5250:\tlearn: 5.8919602\ttest: 5.8580204\tbest: 5.8580171 (5244)\ttotal: 2h 11m 39s\tremaining: 1h 59m 4s\n",
      "5300:\tlearn: 5.8900086\ttest: 5.8580249\tbest: 5.8580171 (5244)\ttotal: 2h 12m 51s\tremaining: 1h 57m 46s\n",
      "5350:\tlearn: 5.8881825\ttest: 5.8580129\tbest: 5.8580072 (5314)\ttotal: 2h 14m 3s\tremaining: 1h 56m 27s\n",
      "5400:\tlearn: 5.8862224\ttest: 5.8579950\tbest: 5.8579899 (5388)\ttotal: 2h 15m 15s\tremaining: 1h 55m 10s\n",
      "5450:\tlearn: 5.8843817\ttest: 5.8579817\tbest: 5.8579808 (5447)\ttotal: 2h 16m 26s\tremaining: 1h 53m 51s\n",
      "5500:\tlearn: 5.8825607\ttest: 5.8579885\tbest: 5.8579808 (5447)\ttotal: 2h 17m 39s\tremaining: 1h 52m 35s\n",
      "5550:\tlearn: 5.8808566\ttest: 5.8579800\tbest: 5.8579787 (5549)\ttotal: 2h 18m 48s\tremaining: 1h 51m 14s\n",
      "5600:\tlearn: 5.8790702\ttest: 5.8579811\tbest: 5.8579674 (5571)\ttotal: 2h 19m 58s\tremaining: 1h 49m 55s\n",
      "5650:\tlearn: 5.8773155\ttest: 5.8579921\tbest: 5.8579674 (5571)\ttotal: 2h 21m 8s\tremaining: 1h 48m 36s\n",
      "5700:\tlearn: 5.8755776\ttest: 5.8579799\tbest: 5.8579674 (5571)\ttotal: 2h 22m 18s\tremaining: 1h 47m 18s\n",
      "5750:\tlearn: 5.8737972\ttest: 5.8579729\tbest: 5.8579674 (5571)\ttotal: 2h 23m 28s\tremaining: 1h 46m\n",
      "5800:\tlearn: 5.8721279\ttest: 5.8579669\tbest: 5.8579613 (5787)\ttotal: 2h 24m 40s\tremaining: 1h 44m 43s\n",
      "5850:\tlearn: 5.8704961\ttest: 5.8579693\tbest: 5.8579613 (5787)\ttotal: 2h 25m 51s\tremaining: 1h 43m 25s\n",
      "5900:\tlearn: 5.8688878\ttest: 5.8579808\tbest: 5.8579613 (5787)\ttotal: 2h 27m 1s\tremaining: 1h 42m 7s\n",
      "5950:\tlearn: 5.8672775\ttest: 5.8579768\tbest: 5.8579613 (5787)\ttotal: 2h 28m 15s\tremaining: 1h 40m 52s\n",
      "6000:\tlearn: 5.8655649\ttest: 5.8579872\tbest: 5.8579613 (5787)\ttotal: 2h 29m 25s\tremaining: 1h 39m 34s\n",
      "Stopped by overfitting detector  (250 iterations wait)\n",
      "\n",
      "bestTest = 5.857961324\n",
      "bestIteration = 5787\n",
      "\n",
      "Shrink model to first 5788 iterations.\n",
      "Catboost Ensemble Mean Absolute Error: 5.85796\n",
      "Catboost Ensemble + PP Mean Absolute Error: 5.85791\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(models_path, exist_ok=True)\n",
    "models = []\n",
    "for i in range(num_models[\"cat\"]):\n",
    "    rnd_state = 42 + i\n",
    "    print(f\"Training model {i+1} out of {num_models['cat']} with seed {rnd_state}\")\n",
    "    print(\"---------------------------------------\")\n",
    "\n",
    "    params[\"random_state\"] = rnd_state\n",
    "\n",
    "    model = CatBoostRegressor(**params)\n",
    "\n",
    "    if os.path.exists(f\"{models_path}/model_cat_{i}.cbm\"):\n",
    "        model.load_model(f\"{models_path}/model_cat_{i}.cbm\")\n",
    "    else:\n",
    "        model.fit(X_train, y_train, eval_set=(X_test, y_test), verbose_eval=50, early_stopping_rounds=250)\n",
    "        model.save_model(f\"{models_path}/model_cat_{i}.cbm\")\n",
    "    models.append(model)\n",
    "\n",
    "    # if dates_train[1] != 480:\n",
    "    #     pred = model.predict(X_test)\n",
    "    #     mae = mean_absolute_error(test_data[\"target\"], pred) # type: ignore\n",
    "    #     print(f\"Mean Absolute Error on test data: {mae:.5f}\")\n",
    "\n",
    "if dates_train[1] != 480:\n",
    "    predictions = make_predictions(models, X_test, model=\"cat\")\n",
    "    print(\n",
    "        f\"Catboost Ensemble Mean Absolute Error: {mean_absolute_error(y_test, predictions):.5f}\"\n",
    "    )\n",
    "    prediction_df = pd.DataFrame(\n",
    "        {\n",
    "            \"stock_id\": X_test[\"stock_id\"],\n",
    "            \"target\": predictions.flatten(),\n",
    "        }\n",
    "    )\n",
    "    weight = json.load(open(\"data/weight.json\"))\n",
    "    weight = dict(zip(range(200), weight))\n",
    "\n",
    "    prediction_df[\"stock_weights\"] = prediction_df[\"stock_id\"].map(weight)\n",
    "    prediction_df[\"target\"] = (\n",
    "        prediction_df[\"target\"]\n",
    "        - (prediction_df[\"target\"] * prediction_df[\"stock_weights\"]).sum()\n",
    "        / prediction_df[\"stock_weights\"].sum()\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"Catboost Ensemble + PP Mean Absolute Error: {mean_absolute_error(y_test, prediction_df['target']):.5f}\"\n",
    "    )\n",
    "    prediction_df.to_parquet(\"output/catboost_predictions.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
