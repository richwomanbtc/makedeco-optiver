{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前処理\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "data_dir = \"./optiver-trading-at-the-close\"\n",
    "train_df = pl.read_csv(\n",
    "    f\"{data_dir}/train.csv\",\n",
    "    dtypes={\n",
    "        \"stock_id\": pl.UInt8,\n",
    "        \"date_id\": pl.UInt16,\n",
    "        \"seconds_in_bucket\": pl.UInt16,\n",
    "        \"reference_price\": pl.Float32,\n",
    "        \"far_price\": pl.Float32,\n",
    "        \"near_price\": pl.Float32,\n",
    "        \"bid_price\": pl.Float32,\n",
    "        \"ask_price\": pl.Float32,\n",
    "        \"wap\": pl.Float32,\n",
    "        \"time_id\": pl.UInt16,\n",
    "        \"target\": pl.Float32,\n",
    "        \"imbalance_buy_sell_flag\": pl.Int8,\n",
    "    },\n",
    ")\n",
    "\n",
    "# indexのウエイト\n",
    "# weight = json.load(open(f\"./weight.json\", \"r\"))\n",
    "# weight_df = pl.DataFrame(\n",
    "#     zip(range(200), weight), schema=[(\"stock_id\", pl.UInt8), (\"weight\", pl.Float32)]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.with_columns(pl.col(\"target\").fill_nan(pl.col(\"target\").median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 17)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>stock_id</th><th>date_id</th><th>seconds_in_bucket</th><th>imbalance_size</th><th>imbalance_buy_sell_flag</th><th>reference_price</th><th>matched_size</th><th>far_price</th><th>near_price</th><th>bid_price</th><th>bid_size</th><th>ask_price</th><th>ask_size</th><th>wap</th><th>target</th><th>time_id</th><th>row_id</th></tr><tr><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td></tr></thead><tbody><tr><td>0</td><td>0</td><td>0</td><td>220</td><td>0</td><td>220</td><td>220</td><td>2894342</td><td>2857180</td><td>220</td><td>0</td><td>220</td><td>0</td><td>220</td><td>0</td><td>0</td><td>0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 17)\n",
       "┌──────────┬─────────┬───────────────────┬────────────────┬───┬─────┬────────┬─────────┬────────┐\n",
       "│ stock_id ┆ date_id ┆ seconds_in_bucket ┆ imbalance_size ┆ … ┆ wap ┆ target ┆ time_id ┆ row_id │\n",
       "│ ---      ┆ ---     ┆ ---               ┆ ---            ┆   ┆ --- ┆ ---    ┆ ---     ┆ ---    │\n",
       "│ u32      ┆ u32     ┆ u32               ┆ u32            ┆   ┆ u32 ┆ u32    ┆ u32     ┆ u32    │\n",
       "╞══════════╪═════════╪═══════════════════╪════════════════╪═══╪═════╪════════╪═════════╪════════╡\n",
       "│ 0        ┆ 0       ┆ 0                 ┆ 220            ┆ … ┆ 220 ┆ 0      ┆ 0       ┆ 0      │\n",
       "└──────────┴─────────┴───────────────────┴────────────────┴───┴─────┴────────┴─────────┴────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.null_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from itertools import combinations\n",
    "from typing import Tuple\n",
    "\n",
    "# @title Feature Engineering Functions\n",
    "\n",
    "\n",
    "def lag_function(\n",
    "    df: pl.DataFrame, columns_to_lag: List[str], num_days_to_lag: List[int]\n",
    ") -> pl.DataFrame:\n",
    "    cols = [\n",
    "        pl.col(columns_to_lag)\n",
    "        .shift(i)\n",
    "        .over([\"stock_id\", \"seconds_in_bucket\"])\n",
    "        .name.prefix(f\"lag{i}_\")\n",
    "        for i in num_days_to_lag\n",
    "    ]\n",
    "    return df.with_columns(*cols)\n",
    "\n",
    "\n",
    "def create_diff_lagged_features_within_date(\n",
    "    df: pl.DataFrame, columns_to_lag: List[str], lags: List[int]\n",
    ") -> pl.DataFrame:\n",
    "    cols = [\n",
    "        pl.col(columns_to_lag)\n",
    "        .sub(pl.col(columns_to_lag).shift(lag).over([\"stock_id\", \"date_id\"]))\n",
    "        .name.suffix(f\"_lag_{lag}\")\n",
    "        for lag in lags\n",
    "    ]\n",
    "    return df.with_columns(*cols)\n",
    "\n",
    "\n",
    "def create_features_from_start(df: pl.DataFrame, columns: List[str]) -> pl.DataFrame:\n",
    "    return df.with_columns(\n",
    "        pl.col(columns)\n",
    "        .sub(pl.col(columns).first().over([\"stock_id\", \"date_id\"]))\n",
    "        .name.suffix(\"_from_start\")\n",
    "    )\n",
    "\n",
    "\n",
    "def compute_imbalances(df: pl.DataFrame, columns: List[str], prefix=\"\") -> pl.DataFrame:\n",
    "    cols = []\n",
    "    for col1, col2 in combinations(columns, 2):\n",
    "        col1, col2 = sorted([col1, col2])\n",
    "        total = pl.col(col1).add(pl.col(col2))\n",
    "        col_name = f\"{col1}_{col2}_imbalance_{prefix}\"\n",
    "        c = pl.col(col1).sub(pl.col(col2)).truediv(total)\n",
    "        cols.append(pl.when(c.is_infinite()).then(float(\"nan\")).otherwise(c).alias(col_name))\n",
    "    return df.with_columns(*cols)\n",
    "\n",
    "\n",
    "def compute_percentage_difference(\n",
    "    df: pl.DataFrame, columns: Tuple[str, str], prefix=\"\"\n",
    ") -> pl.DataFrame:\n",
    "    cols = []\n",
    "    for col1, col2 in combinations(columns, 2):\n",
    "        col1, col2 = sorted([col1, col2])\n",
    "        col_name = f\"{col1}_{col2}_percentage_difference_{prefix}\"\n",
    "        cols.append(\n",
    "            pl.col(col1).sub(pl.col(col2)).truediv(pl.col(col2)).alias(col_name)\n",
    "        )\n",
    "    return df.with_columns(*cols)\n",
    "\n",
    "\n",
    "def create_cumsum_features(df: pl.DataFrame, columns: List[str]) -> pl.DataFrame:\n",
    "    return df.with_columns(\n",
    "        pl.col(columns).cum_sum().over([\"stock_id\", \"date_id\"]).name.suffix(\"_cumsum\")\n",
    "    )\n",
    "\n",
    "\n",
    "def create_deviation_within_seconds(\n",
    "    df: pl.DataFrame,\n",
    "    columns: List[str],\n",
    ") -> pl.DataFrame:\n",
    "    return df.with_columns(\n",
    "        pl.col(columns)\n",
    "        .sub(\n",
    "            pl.col(columns).median().over([\"date_id\", \"seconds_in_bucket\"])\n",
    "        )\n",
    "        .name.suffix(\"_deviation\")\n",
    "    )\n",
    "\n",
    "\n",
    "def feature_engineering(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    return df.with_columns(\n",
    "        spread_eng=pl.col(\"ask_price\").sub(pl.col(\"bid_price\")),\n",
    "        volume_eng=pl.col(\"ask_size\").add(pl.col(\"bid_size\")),\n",
    "        volumne_imbalance_eng=pl.col(\"bid_size\").sub(pl.col(\"ask_size\")),\n",
    "        imbalance_ratio=pl.col(\"imbalance_size\").truediv(pl.col(\"matched_size\")),\n",
    "        price_spread_near_far=pl.col(\"near_price\").sub(pl.col(\"far_price\")),\n",
    "        price_wap_difference_eng=pl.col(\"reference_price\").sub(pl.col(\"wap\")),\n",
    "        weighted_imbalance_eng=pl.col(\"imbalance_size\").mul(\n",
    "            pl.col(\"imbalance_buy_sell_flag\")\n",
    "        ),\n",
    "        bid_ask_ratio=pl.col(\"bid_size\").truediv(pl.col(\"ask_size\")),\n",
    "        imbalance_to_bid_ratio_eng=pl.col(\"imbalance_size\").truediv(pl.col(\"bid_size\")),\n",
    "        imbalance_to_ask_ratio_eng=pl.col(\"imbalance_size\").truediv(pl.col(\"ask_size\")),\n",
    "        matched_size_to_total_size_ratio_eng=pl.col(\"matched_size\").truediv(\n",
    "            pl.col(\"bid_size\").add(pl.col(\"ask_size\"))\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_describe(columns) -> List:\n",
    "    cols = []\n",
    "    for col in columns:\n",
    "        prefix = f\"{col}_\"\n",
    "        cols.extend(\n",
    "            [\n",
    "                pl.col(col).mean().alias(f\"{prefix}mean\"),\n",
    "                pl.col(col).std().alias(f\"{prefix}std\"),\n",
    "                pl.col(col).min().alias(f\"{prefix}min\"),\n",
    "                pl.col(col).quantile(0.25).alias(f\"{prefix}q25\"),\n",
    "                pl.col(col).median().alias(f\"{prefix}median\"),\n",
    "                pl.col(col).quantile(0.75).alias(f\"{prefix}q75\"),\n",
    "                pl.col(col).max().alias(f\"{prefix}max\"),\n",
    "            ]\n",
    "        )\n",
    "    return cols\n",
    "\n",
    "\n",
    "def global_features(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    columns = [\"bid_size\", \"ask_size\", \"bid_price\", \"ask_price\"]\n",
    "    groupby_cols = [\"stock_id\"]\n",
    "    global_features_df = (\n",
    "        df.group_by(groupby_cols).agg(to_describe(columns)).sort(\"stock_id\")\n",
    "    )\n",
    "    global_features_df = global_features_df.with_columns(\n",
    "        median_size=pl.col(\"bid_size_median\").add(pl.col(\"ask_size_median\")),\n",
    "        std_size=pl.col(\"bid_size_std\").add(pl.col(\"ask_size_std\")),\n",
    "        ptp_size=pl.col(\"bid_size_max\").sub(pl.col(\"ask_size_min\")),\n",
    "        median_price=pl.col(\"bid_price_median\").add(pl.col(\"ask_price_median\")),\n",
    "        std_price=pl.col(\"bid_price_std\").add(pl.col(\"ask_price_std\")),\n",
    "        ptp_price=pl.col(\"bid_price_max\").sub(pl.col(\"ask_price_min\")),\n",
    "    )\n",
    "    return df.join(global_features_df, on=\"stock_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_stat_lag(df: pl.DataFrame, num_lags: int) -> pl.DataFrame:\n",
    "    lags = [f\"lag{i}_target\" for i in range(1, num_lags + 1)]\n",
    "    l = pl.concat_list(lags)\n",
    "    return df.with_columns(\n",
    "        target_mean=pl.mean_horizontal(*lags),\n",
    "        target_range=pl.max_horizontal(*lags).sub(pl.min_horizontal(*lags)),\n",
    "        target_std=l.list.eval(pl.element().std()).list.first(),\n",
    "        target_variance=l.list.eval(pl.element().var()).list.first(),\n",
    "        target_median=l.list.eval(pl.element().median()).list.first(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_date(df: pl.DataFrame, dates: Tuple[int, int]) -> pl.DataFrame:\n",
    "    return df.filter(\n",
    "        pl.col(\"date_id\").ge(dates[0]).and_(pl.col(\"date_id\").le(dates[1]))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from polars import DataFrame\n",
    "\n",
    "\n",
    "raw_cols = [\n",
    "    \"imbalance_size\",\n",
    "    \"matched_size\",\n",
    "    \"bid_size\",\n",
    "    \"ask_size\",\n",
    "    \"reference_price\",\n",
    "    \"far_price\",\n",
    "    \"near_price\",\n",
    "    \"bid_price\",\n",
    "    \"ask_price\",\n",
    "    \"wap\",\n",
    "    \"imbalance_buy_sell_flag\",\n",
    "]\n",
    "columns_prices = [\n",
    "    \"reference_price\",\n",
    "    \"far_price\",\n",
    "    \"near_price\",\n",
    "    \"bid_price\",\n",
    "    \"ask_price\",\n",
    "    \"wap\",\n",
    "]\n",
    "columns_4prices = [\"reference_price\", \"bid_price\", \"ask_price\", \"wap\"]\n",
    "\n",
    "columns_sizes = [\"imbalance_size\", \"matched_size\", \"bid_size\", \"ask_size\"]\n",
    "columns_flag = [\"imbalance_buy_sell_flag\"]\n",
    "\n",
    "\n",
    "diff_lags = [1, 2, 3, 6, 12, 18, 24]\n",
    "diff_lags_extra = [30, 36, 42, 48]\n",
    "\n",
    "num_of_target_lags = 12\n",
    "target_lags = list(range(1, num_of_target_lags + 1))\n",
    "\n",
    "\n",
    "def feature_pipeline(df: pl.DataFrame) -> pl.DataFrame:\n",
    "\n",
    "    df = feature_engineering(df)\n",
    "    df = compute_imbalances(df, columns_sizes, prefix=\"_sz_\")\n",
    "    df = compute_imbalances(df, columns_prices, prefix=\"_pr_\")\n",
    "    eng_features = [c for c in df.schema.keys() if \"_eng\" in c]\n",
    "    imb_features_all = [c for c in df.schema.keys() if \"_imb_\" in c]\n",
    "    imb_features_price = [c for c in df.schema.keys() if \"_pr_\" in c]\n",
    "    imb_features_size = [c for c in df.schema.keys() if \"_sz_\" in c]\n",
    "\n",
    "    diff_lag_cols = raw_cols + eng_features\n",
    "    print(f\"diff lagging {len(diff_lag_cols)} columns for {len(diff_lags)} lags.\")\n",
    "    df = create_diff_lagged_features_within_date(df, diff_lag_cols, diff_lags)\n",
    "\n",
    "    cumsum_columns = columns_sizes + imb_features_size + eng_features\n",
    "    print(f\"cumsum for {len(cumsum_columns)} cols.\")\n",
    "    df = create_cumsum_features(df, cumsum_columns)\n",
    "\n",
    "    deviation_cols = raw_cols + eng_features + imb_features_size  # + imb_features_price\n",
    "    print(f\"deviation {len(deviation_cols)} columns within seconds.\")\n",
    "    df = create_deviation_within_seconds(df, deviation_cols)\n",
    "\n",
    "    print(f\"lagging target column for {len(target_lags)} lags.\")\n",
    "    df = lag_function(df, [\"target\"], target_lags)\n",
    "\n",
    "    df = global_features(df)\n",
    "    df = calculate_stat_lag(df, num_lags=num_of_target_lags)\n",
    "    return df.with_columns(\n",
    "        pl.when(pl.col(col).is_infinite())\n",
    "        .then(np.nan)\n",
    "        .otherwise(pl.col(col))\n",
    "        .alias(col)\n",
    "        for col, value in df.schema.items()\n",
    "        if value in [pl.Float32, pl.Float64]\n",
    "    )\n",
    "\n",
    "\n",
    "def feature_pipeline_rnn(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    df = compute_imbalances(df, columns_sizes, prefix=\"_sz_\")\n",
    "    df = compute_imbalances(df, columns_prices, prefix=\"_pr_\")\n",
    "    num_of_target_lags = 3\n",
    "    target_lags = list(range(1, num_of_target_lags + 1))\n",
    "    print(f\"lagging target column for {len(target_lags)} lags.\")\n",
    "    df = lag_function(df, [\"target\"], target_lags)\n",
    "    eng_features = [c for c in df.schema.keys() if \"_eng\" in c]\n",
    "    imb_features_size = [c for c in df.schema.keys() if \"_sz_\" in c]\n",
    "    deviation_cols = raw_cols + eng_features + imb_features_size\n",
    "    df = create_deviation_within_seconds(df, deviation_cols)\n",
    "    df = global_features(df)    \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff lagging 19 columns for 7 lags.\n",
      "cumsum for 18 cols.\n",
      "deviation 25 columns within seconds.\n",
      "lagging target column for 12 lags.\n"
     ]
    }
   ],
   "source": [
    "feature_df = feature_pipeline(train_df)\n",
    "with open(f\"data/train_eng.parquet\", \"wb\") as f:\n",
    "    feature_df.write_parquet(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lagging target column for 3 lags.\n"
     ]
    }
   ],
   "source": [
    "rnn_feature_df = feature_pipeline_rnn(train_df)\n",
    "with open(f\"data/train_eng_rnn.parquet\", \"wb\") as f:\n",
    "    rnn_feature_df.write_parquet(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
