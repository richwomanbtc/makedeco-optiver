{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import lightgbm as lgb\n",
    "from typing import Tuple, List, Dict\n",
    "import os\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_train = (0, 400)\n",
    "dates_test = (401, 480)\n",
    "num_models = {\"lgb\": 1}\n",
    "models_path = \"./models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title params dashboard\n",
    "lgb_params = {\n",
    "    \"learning_rate\": 0.005,  # 0.005,0.05\n",
    "    \"max_depth\": 14,  # 14\n",
    "    \"n_estimators\": 5000,\n",
    "    \"num_leaves\": 1023,  # 511,31,1023\n",
    "    \"objective\": \"mae\",\n",
    "    \"subsample\": 0.2,\n",
    "    \"colsample_bytree\": 0.3,\n",
    "    \"num_threads\": 7,\n",
    "    # \"device\": \"gpu\",\n",
    "    # 'reg_alpha'         : 0.1,\n",
    "    # 'reg_lambda'        : 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_date(df: pl.DataFrame, dates: Tuple[int, int]) -> pl.DataFrame:\n",
    "    return df.filter(\n",
    "        pl.col(\"date_id\").ge(dates[0]).and_(pl.col(\"date_id\").le(dates[1]))\n",
    "    )\n",
    "\n",
    "\n",
    "def make_predictions(models, X_test, model=\"nn\"):\n",
    "    if model == \"nn\":\n",
    "        all_predictions = [model.predict(X_test, batch_size=16384) for model in models]\n",
    "    if model == \"lgb\":\n",
    "        all_predictions = [\n",
    "            model.predict(X_test, num_iteration=model.best_iteration)\n",
    "            for model in models\n",
    "        ]\n",
    "    if model == \"xgb\":\n",
    "        all_predictions = [\n",
    "            model.predict(\n",
    "                X_test, iteration_range=(0, model.get_booster().best_iteration + 1)\n",
    "            )\n",
    "            for model in models\n",
    "        ]\n",
    "    if model == \"cat\":\n",
    "        all_predictions = [model.predict(X_test) for model in models]\n",
    "    prediction = np.mean(all_predictions, axis=0)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded_columns = [\"row_id\", \"date_id\", \"time_id\", \"target\", \"stock_return\"]\n",
    "\n",
    "train_eng = pl.read_parquet(\"data/train_eng.parquet\")\n",
    "lgb_features = [\n",
    "    col for col in train_eng.schema.keys() if col not in excluded_columns\n",
    "]\n",
    "categorical_features = [\"seconds_in_bucket\"]\n",
    "\n",
    "print(\"we have {} lgb features\".format(len(lgb_features)))\n",
    "\n",
    "train_data = split_by_date(train_eng, dates_train)\n",
    "test_data = split_by_date(train_eng, dates_test)\n",
    "\n",
    "\n",
    "\n",
    "X_train, y_train = (\n",
    "    train_data.select(pl.col(lgb_features)).to_numpy(),\n",
    "    train_data.select(pl.col(\"target\")).to_numpy(),\n",
    ")\n",
    "X_test, y_test = (\n",
    "    test_data.select(pl.col(lgb_features)).to_numpy(),\n",
    "    test_data.select(pl.col(\"target\")).to_numpy(),\n",
    "        )\n",
    "train_set = lgb.Dataset(\n",
    "    X_train,\n",
    "    label=y_train,\n",
    "    # categorical_feature=categorical_features,\n",
    "    free_raw_data=False,\n",
    ")\n",
    "test_set = lgb.Dataset(\n",
    "    X_test,\n",
    "    label=y_test,\n",
    "    # categorical_feature=categorical_features,\n",
    "    free_raw_data=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm.callback import log_evaluation, early_stopping\n",
    "\n",
    "os.makedirs(models_path, exist_ok=True)\n",
    "\n",
    "lgb_models = []\n",
    "for i in range(num_models[\"lgb\"]):\n",
    "    rnd_state = 42 + i\n",
    "\n",
    "    lgb_params[\"random_state\"] = rnd_state\n",
    "    if os.path.exists(f\"{models_path}/model_lgb_{i}.txt\"):\n",
    "        lgb_model = lgb.Booster(model_file=f\"{models_path}/model_lgb_{i}.txt\")\n",
    "        print(f\"Loaded model {i+1} out of {num_models['lgb']}\")\n",
    "    else:\n",
    "        print(\n",
    "            f\"Training model {i+1} out of {num_models['lgb']} with seed {rnd_state}\"\n",
    "        )\n",
    "        print(\"---------------------------------------\")\n",
    "        lgb_model = lgb.train(\n",
    "            lgb_params,\n",
    "            train_set,\n",
    "            init_model=None,\n",
    "            valid_sets=[train_set, test_set],\n",
    "            callbacks=[log_evaluation(50), early_stopping(250)],\n",
    "        )\n",
    "        lgb_model.save_model(f\"{models_path}/model_lgb_{i}.txt\")\n",
    "    lgb_models.append(lgb_model)\n",
    "\n",
    "    # if dates_train[1] != 480:\n",
    "    #     pred = lgb_model.predict(X_test)\n",
    "    #     mae = mean_absolute_error(test_data[\"target\"], pred) # type: ignore\n",
    "    #     print(f\"Mean Absolute Error on test data: {mae:.5f}\")\n",
    "\n",
    "if dates_train[1] != 480:\n",
    "    predictions = make_predictions(\n",
    "        lgb_models, X_test, model=\"lgb\"\n",
    "    )\n",
    "    print(\n",
    "        f\"LGB Ensemble Mean Absolute Error: {mean_absolute_error(y_test, predictions):.5f}\"\n",
    "    )\n",
    "    prediction_df = pd.DataFrame(\n",
    "        {\n",
    "            \"stock_id\": test_data[\"stock_id\"],\n",
    "            \"target\": predictions.flatten(),\n",
    "        }\n",
    "    )\n",
    "    weight = json.load(open(\"data/weight.json\"))\n",
    "    weight = dict(zip(range(200), weight))\n",
    "\n",
    "    prediction_df[\"stock_weights\"] = prediction_df[\"stock_id\"].map(weight)\n",
    "    prediction_df[\"target\"] = (\n",
    "        prediction_df[\"target\"]\n",
    "        - (prediction_df[\"target\"] * prediction_df[\"stock_weights\"]).sum()\n",
    "        / prediction_df[\"stock_weights\"].sum()\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"LGB Ensemble + PP Mean Absolute Error: {mean_absolute_error(y_test, prediction_df['target']):.5f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df.to_parquet(f\"output/lgb_predictions.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "fi = pd.Series(\n",
    "    dict(\n",
    "        zip(\n",
    "            lgb_features,\n",
    "            lgb_models[0].feature_importance(importance_type=\"gain\"),\n",
    "        )\n",
    "    )\n",
    ").sort_values(ascending=False).iloc[:20]\n",
    "fi.plot(kind=\"barh\", figsize=(10, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi.plot.bar(figsize=(20, 10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
