{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from typing import Tuple, List, Dict\n",
    "import os\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_train = (0, 400)\n",
    "dates_test = (401, 480)\n",
    "num_models = {\"xgb\": 1}\n",
    "models_path = \"./models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title params dashboard\n",
    "params = {\n",
    "    \"eta\": 0.005,  # 0.005,0.05\n",
    "    \"max_depth\": 14,  # 14\n",
    "    \"n_estimators\": 5000,\n",
    "    \"max_leaves\": 1023,  # 511,31,1023\n",
    "    \"objective\": \"reg:absoluteerror\",\n",
    "    \"subsample\": 0.2,\n",
    "    \"colsample_bytree\": 0.3,\n",
    "    \"nthread\": 6,\n",
    "    \"enable_categorical\": True,\n",
    "    \"eval_metric\": \"mae\",\n",
    "    \"early_stopping_rounds\": 250,\n",
    "    \"device\": \"gpu\",\n",
    "    # 'reg_alpha'         : 0.1,\n",
    "    # 'reg_lambda'        : 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_date(df: pl.DataFrame, dates: Tuple[int, int]) -> pl.DataFrame:\n",
    "    return df.filter(\n",
    "        pl.col(\"date_id\").ge(dates[0]).and_(pl.col(\"date_id\").le(dates[1]))\n",
    "    )\n",
    "\n",
    "\n",
    "def make_predictions(models, X_test, model=\"nn\"):\n",
    "    if model == \"nn\":\n",
    "        all_predictions = [model.predict(X_test, batch_size=16384) for model in models]\n",
    "    if model == \"lgb\":\n",
    "        all_predictions = [\n",
    "            model.predict(X_test, num_iteration=model.best_iteration)\n",
    "            for model in models\n",
    "        ]\n",
    "    if model == \"xgb\":\n",
    "        all_predictions = [\n",
    "            model.predict(\n",
    "                X_test, iteration_range=(0, model.get_booster().best_iteration + 1)\n",
    "            )\n",
    "            for model in models\n",
    "        ]\n",
    "    if model == \"cat\":\n",
    "        all_predictions = [model.predict(X_test) for model in models]\n",
    "    prediction = np.mean(all_predictions, axis=0)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have 272 xgb features\n"
     ]
    }
   ],
   "source": [
    "excluded_columns = [\"row_id\", \"date_id\", \"time_id\", \"target\", \"stock_return\"]\n",
    "\n",
    "train_eng = pl.read_parquet(\"data/train_eng.parquet\")\n",
    "lgb_features = [\n",
    "    col for col in train_eng.schema.keys() if col not in excluded_columns\n",
    "]\n",
    "categorical_features = [\"seconds_in_bucket\"]\n",
    "\n",
    "print(\"we have {} xgb features\".format(len(lgb_features)))\n",
    "\n",
    "train_data = split_by_date(train_eng, dates_train)\n",
    "test_data = split_by_date(train_eng, dates_test)\n",
    "\n",
    "\n",
    "X_train, y_train = (\n",
    "    train_data.select(pl.col(lgb_features)).to_pandas(),\n",
    "    train_data.select(pl.col(\"target\")).to_pandas(),\n",
    ")\n",
    "X_test, y_test = (\n",
    "    test_data.select(pl.col(lgb_features)).to_pandas(),\n",
    "    test_data.select(pl.col(\"target\")).to_pandas(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3563"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[categorical_features] = X_train[categorical_features].astype(\"category\")\n",
    "X_test[categorical_features] = X_test[categorical_features].astype(\"category\")\n",
    "\n",
    "del train_data, test_data, train_eng\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 1 out of 1 with seed 42\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Ensemble Mean Absolute Error: 5.84710\n",
      "XGB Ensemble + PP Mean Absolute Error: 5.84709\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(models_path, exist_ok=True)\n",
    "models = []\n",
    "for i in range(num_models[\"xgb\"]):\n",
    "    rnd_state = 42 + i\n",
    "    print(\n",
    "        f\"Training model {i+1} out of {num_models['xgb']} with seed {rnd_state}\"\n",
    "    )\n",
    "    print(\"---------------------------------------\")\n",
    "\n",
    "    params[\"random_state\"] = rnd_state\n",
    "\n",
    "    model = XGBRegressor(**params)\n",
    "\n",
    "    if os.path.exists(f\"{models_path}/model_xgb_{i}.json\"):\n",
    "        model.load_model(f\"{models_path}/model_xgb_{i}.json\")\n",
    "    else:\n",
    "        model.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            eval_set=[(X_test, y_test)],\n",
    "            verbose=1,\n",
    "        )\n",
    "        model.save_model(f\"{models_path}/model_xgb_{i}.json\")\n",
    "    models.append(model)\n",
    "\n",
    "    # if dates_train[1] != 480:\n",
    "    #     pred = model.predict(X_test)\n",
    "    #     mae = mean_absolute_error(test_data[\"target\"], pred) # type: ignore\n",
    "    #     print(f\"Mean Absolute Error on test data: {mae:.5f}\")\n",
    "\n",
    "if dates_train[1] != 480:\n",
    "    predictions = make_predictions(models, X_test, model=\"xgb\")\n",
    "    print(\n",
    "        f\"XGB Ensemble Mean Absolute Error: {mean_absolute_error(y_test, predictions):.5f}\"\n",
    "    )\n",
    "    prediction_df = pd.DataFrame(\n",
    "        {\n",
    "            \"stock_id\": X_test[\"stock_id\"],\n",
    "            \"target\": predictions.flatten(),\n",
    "        }\n",
    "    )\n",
    "    weight = json.load(open(\"data/weight.json\"))\n",
    "    weight = dict(zip(range(200), weight))\n",
    "\n",
    "    prediction_df[\"stock_weights\"] = prediction_df[\"stock_id\"].map(weight)\n",
    "    prediction_df[\"target\"] = (\n",
    "        prediction_df[\"target\"]\n",
    "        - (prediction_df[\"target\"] * prediction_df[\"stock_weights\"]).sum()\n",
    "        / prediction_df[\"stock_weights\"].sum()\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"XGB Ensemble + PP Mean Absolute Error: {mean_absolute_error(y_test, prediction_df['target']):.5f}\"\n",
    "    )\n",
    "    prediction_df.to_parquet(\"output/xgb_predictions.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Ensemble Mean Absolute Error: 5.84710\n",
      "XGB Ensemble + PP Mean Absolute Error: 5.84709\n"
     ]
    }
   ],
   "source": [
    "predictions = make_predictions(models, X_test, model=\"xgb\")\n",
    "print(\n",
    "    f\"XGB Ensemble Mean Absolute Error: {mean_absolute_error(y_test, predictions):.5f}\"\n",
    ")\n",
    "prediction_df = pd.DataFrame(\n",
    "    {\n",
    "        \"stock_id\": X_test[\"stock_id\"],\n",
    "        \"target\": predictions.flatten(),\n",
    "    }\n",
    ")\n",
    "\n",
    "weight = json.load(open(f\"data/weight.json\"))\n",
    "weight = dict(zip(range(200), weight))\n",
    "\n",
    "prediction_df[\"stock_weights\"] = prediction_df[\"stock_id\"].map(weight)\n",
    "prediction_df[\"target\"] = (\n",
    "    prediction_df[\"target\"]\n",
    "    - (prediction_df[\"target\"] * prediction_df[\"stock_weights\"]).sum()\n",
    "    / prediction_df[\"stock_weights\"].sum()\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"XGB Ensemble + PP Mean Absolute Error: {mean_absolute_error(y_test, prediction_df['target']):.5f}\"\n",
    ")\n",
    "prediction_df.to_parquet(\"output/xgb_predictions.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
